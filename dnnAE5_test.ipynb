{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_attack_intensity = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ae import AE\n",
    "from models.dnnAE import DNN\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to all dataset\n",
    "DATASET_PATH = os.path.join(os.getcwd(), 'data')\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.path.join(os.getcwd(), 'checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DNN Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = defaultdict(dict)\n",
    "for severity in tqdm(range(5,10), desc='Reading data ... '):\n",
    "    ATTACK_DATA_PATH = os.path.join(DATASET_PATH, f'I{severity}')\n",
    "    for filename in os.listdir(ATTACK_DATA_PATH):\n",
    "        fname = os.path.join(ATTACK_DATA_PATH, filename)\n",
    "        data = loadmat(fname)\n",
    "        att_type = int(re.findall(r'\\d+', filename)[0])\n",
    "        Z[severity][att_type] = data['Z']\n",
    "\n",
    "NORMAL_DATA_FILENAME = 'Normal2.mat'\n",
    "data = loadmat(os.path.join(DATASET_PATH, NORMAL_DATA_FILENAME))\n",
    "Z[0] = data['Z']\n",
    "\n",
    "Z = dict(sorted(Z.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 118\n",
    "no_residuals = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Trained Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0, 5, 10, 20, 50]\n",
    "aes = dict()\n",
    "for level in noise_levels:\n",
    "    ae = AE(latent_dim).to(device)\n",
    "    ae.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, f'ae_{level}%.pt')))\n",
    "    aes[level] = ae\n",
    "\n",
    "dnn = DNN(no_residuals=no_residuals).to(device)\n",
    "dnn.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, f'dnn_{dnn_attack_intensity}.pt')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Normal Sensor Data To DNN Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_normal = defaultdict()\n",
    "for level in tqdm(noise_levels, desc=' Generating residuals ... '):\n",
    "    ae = aes[level].eval()\n",
    "    z = torch.tensor(Z[0], dtype=torch.float32).to(device)\n",
    "    # AE residuals for normal data\n",
    "    r = (ae(z) - z)\n",
    "    pred_normal[level] = dnn(torch.stack([r], dim=1)).detach().cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Attack Sensor Data To DNN Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = defaultdict()\n",
    "for level in tqdm(noise_levels, desc=' Generating residuals ... '):\n",
    "    vae = vaes[level].eval()\n",
    "    rnn = rnns[level].eval()\n",
    "    for severity in range(5,10):\n",
    "        _Z, _RES = Z[severity], RES[severity]\n",
    "        R = defaultdict(list)\n",
    "        for k, v in _Z.items():\n",
    "            # state estimation residual\n",
    "            r1 = torch.tensor(_RES[k], dtype=torch.float32)\n",
    "            z = torch.tensor(v, dtype=torch.float32).to(device)\n",
    "            _R = []\n",
    "            for _ in range(samples):\n",
    "                # VAE residuals\n",
    "                z_rec = vae(z)\n",
    "                r2 = (z_rec - z).detach().cpu()\n",
    "                \n",
    "                # rnn prediction residual\n",
    "                s_t = vae.encoder(z).cpu().detach().numpy()\n",
    "                s_t = series_to_supervised(s_t, n_in=rnn_window).values[:,:rnn_window * latent_dim]\n",
    "                s_t = torch.tensor(s_t, dtype=torch.float32).to(device)\n",
    "                z_rnn = vae.decoder(rnn(s_t))\n",
    "                r3 = (z_rnn - z[rnn_window:]).detach().cpu()\n",
    "                _R.append(torch.stack([r1[rnn_window:],r2[rnn_window:],r3], dim=1))\n",
    "            R[k] = torch.stack(_R, dim=1)\n",
    "        R = dict(sorted(R.items()))\n",
    "        _pred = dnn(torch.cat(list(R.values()), dim=0).to(device))\n",
    "        pred[level,severity] = torch.cat([pred_normal[level].cpu(), _pred.cpu()], dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "no_signal = len(Z[0]) - rnn_window\n",
    "for l in range(4):\n",
    "    y.append(F.one_hot(l * torch.ones((no_signal), dtype=torch.long), num_classes=4))\n",
    "y = torch.cat(y, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DNN Evaluation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Confusion Matrices**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix: Noise Level 0%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "level = 0\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "level = 0\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "level = 0\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "level = 0\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "level = 0\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix: Noise Level 5%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "level = 5\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "level = 5\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "level = 5\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "level = 5\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "level = 5\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix: Noise Level 10%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "level = 10\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "level = 10\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "level = 10\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "level = 10\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "level = 10\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix: Noise Level 20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "level = 20\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "level = 20\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "level = 20\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "level = 20\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "level = 20\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix: Noise Level 50%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "level = 50\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "level = 50\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "level = 50\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "level = 50\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "level = 50\n",
    "pp = torch.argmax(pred[level,severity], dim=1).numpy()\n",
    "yy = torch.argmax(y, dim=1).numpy()\n",
    "# report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.classification_report(yy, pp, zero_division=0))\n",
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(yy,pp, labels=[0,1,2,3])\n",
    "print(\"Confusion Matrix:\")\n",
    "metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3]).plot()\n",
    "plt.show()\n",
    "# roc curve 0 vs. rest\n",
    "chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "yy[yy>0] = 1\n",
    "pp[pp>0] = 1\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    yy,\n",
    "    pp,\n",
    "    name=\"No Attack vs the rest\",\n",
    "    color=\"darkorange\"\n",
    ")\n",
    "plt.plot((0, 1), (0, 1), **chance_level_line_kw)\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves: Attack Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quantiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.tensor([0.025, 0.975])\n",
    "x_ax = ['0%', '%5', '%10', '%20', '50%']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantiles: Attack Severity 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 5\n",
    "mean, low, up = defaultdict(), defaultdict(), defaultdict()\n",
    "_min = defaultdict()\n",
    "for k, v in tqdm(pred.items(),desc=' Generating quantiles ... '):\n",
    "    if k[1] == severity:\n",
    "        for _type in range(4):\n",
    "            _pred = v[_type * no_signal:(_type + 1) * no_signal]\n",
    "            _min_val, _min_id = _pred.min(dim=0)\n",
    "            _min[k[0],_type] = {_min_id[_type].item(): _min_val[_type].item()}\n",
    "            mean[k[0],_type] = _pred.mean(dim=0).numpy()[_type]\n",
    "            _low, _up = torch.quantile(_pred, q, dim=0).numpy()\n",
    "            low[k[0], _type], up[k[0], _type] = _low[_type], _up[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(noise_levels))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25, 4))\n",
    "for _type in range(4):\n",
    "    _m = [mean[l, _type] for l in noise_levels]\n",
    "    _l = [low[l, _type] for l in noise_levels]\n",
    "    _u = [up[l, _type] for l in noise_levels]\n",
    "    ax[_type].plot(x, _l, label='Lower', lw=3, color='g')\n",
    "    ax[_type].plot(x, _u, label='Upper', lw=3, color='b')\n",
    "    ax[_type].plot(x, _m, label='Mean', lw=3, color='r')\n",
    "    ax[_type].fill_between(x, _l, _u, color='r', alpha=0.2)\n",
    "    ax[_type].set(xticks=x, xticklabels=x_ax)\n",
    "    if _type == 0:\n",
    "        ax[_type].title.set_text('Normal Data')\n",
    "    else:\n",
    "        ax[_type].title.set_text(f'Attack Data {_type}')\n",
    "    ax[_type].legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantiles: Attack Severity 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 6\n",
    "mean, low, up = defaultdict(), defaultdict(), defaultdict()\n",
    "for k, v in tqdm(pred.items(),desc=' Generating quantiles ... '):\n",
    "    if k[1] == severity:\n",
    "        for _type in range(4):\n",
    "            _pred = v[_type * no_signal:(_type + 1) * no_signal]\n",
    "            mean[k[0],_type] = _pred.mean(dim=0).numpy()[_type]\n",
    "            _low, _up = torch.quantile(_pred, q, dim=0).numpy()\n",
    "            low[k[0], _type], up[k[0], _type] = _low[_type], _up[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(noise_levels))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25, 4))\n",
    "for _type in range(4):\n",
    "    _m = [mean[l, _type] for l in noise_levels]\n",
    "    _l = [low[l, _type] for l in noise_levels]\n",
    "    _u = [up[l, _type] for l in noise_levels]\n",
    "    ax[_type].plot(x, _l, label='Lower', lw=3, color='g')\n",
    "    ax[_type].plot(x, _u, label='Upper', lw=3, color='b')\n",
    "    ax[_type].plot(x, _m, label='Mean', lw=3, color='r')\n",
    "    ax[_type].fill_between(x, _l, _u, color='r', alpha=0.2)\n",
    "    ax[_type].set(xticks=x, xticklabels=x_ax)\n",
    "    if _type == 0:\n",
    "        ax[_type].title.set_text('Normal Data')\n",
    "    else:\n",
    "        ax[_type].title.set_text(f'Attack Data {_type}')\n",
    "    ax[_type].legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantiles: Attack Severity 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 7\n",
    "mean, low, up = defaultdict(), defaultdict(), defaultdict()\n",
    "for k, v in tqdm(pred.items(),desc=' Generating quantiles ... '):\n",
    "    if k[1] == severity:\n",
    "        for _type in range(4):\n",
    "            _pred = v[_type * no_signal:(_type + 1) * no_signal]\n",
    "            mean[k[0],_type] = _pred.mean(dim=0).numpy()[_type]\n",
    "            _low, _up = torch.quantile(_pred, q, dim=0).numpy()\n",
    "            low[k[0], _type], up[k[0], _type] = _low[_type], _up[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(noise_levels))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25, 4))\n",
    "for _type in range(4):\n",
    "    _m = [mean[l, _type] for l in noise_levels]\n",
    "    _l = [low[l, _type] for l in noise_levels]\n",
    "    _u = [up[l, _type] for l in noise_levels]\n",
    "    ax[_type].plot(x, _l, label='Lower', lw=3, color='g')\n",
    "    ax[_type].plot(x, _u, label='Upper', lw=3, color='b')\n",
    "    ax[_type].plot(x, _m, label='Mean', lw=3, color='r')\n",
    "    ax[_type].fill_between(x, _l, _u, color='r', alpha=0.2)\n",
    "    ax[_type].set(xticks=x, xticklabels=x_ax)\n",
    "    if _type == 0:\n",
    "        ax[_type].title.set_text('Normal Data')\n",
    "    else:\n",
    "        ax[_type].title.set_text(f'Attack Data {_type}')\n",
    "    ax[_type].legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantiles: Attack Severity 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 8\n",
    "mean, low, up = defaultdict(), defaultdict(), defaultdict()\n",
    "for k, v in tqdm(pred.items(),desc=' Generating quantiles ... '):\n",
    "    if k[1] == severity:\n",
    "        for _type in range(4):\n",
    "            _pred = v[_type * no_signal:(_type + 1) * no_signal]\n",
    "            mean[k[0],_type] = _pred.mean(dim=0).numpy()[_type]\n",
    "            _low, _up = torch.quantile(_pred, q, dim=0).numpy()\n",
    "            low[k[0], _type], up[k[0], _type] = _low[_type], _up[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(noise_levels))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25, 4))\n",
    "for _type in range(4):\n",
    "    _m = [mean[l, _type] for l in noise_levels]\n",
    "    _l = [low[l, _type] for l in noise_levels]\n",
    "    _u = [up[l, _type] for l in noise_levels]\n",
    "    ax[_type].plot(x, _l, label='Lower', lw=3, color='g')\n",
    "    ax[_type].plot(x, _u, label='Upper', lw=3, color='b')\n",
    "    ax[_type].plot(x, _m, label='Mean', lw=3, color='r')\n",
    "    ax[_type].fill_between(x, _l, _u, color='r', alpha=0.2)\n",
    "    ax[_type].set(xticks=x, xticklabels=x_ax)\n",
    "    if _type == 0:\n",
    "        ax[_type].title.set_text('Normal Data')\n",
    "    else:\n",
    "        ax[_type].title.set_text(f'Attack Data {_type}')\n",
    "    ax[_type].legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantiles: Attack Severity 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = 9\n",
    "mean, low, up = defaultdict(), defaultdict(), defaultdict()\n",
    "for k, v in tqdm(pred.items(),desc=' Generating quantiles ... '):\n",
    "    if k[1] == severity:\n",
    "        for _type in range(4):\n",
    "            _pred = v[_type * no_signal:(_type + 1) * no_signal]\n",
    "            mean[k[0],_type] = _pred.mean(dim=0).numpy()[_type]\n",
    "            _low, _up = torch.quantile(_pred, q, dim=0).numpy()\n",
    "            low[k[0], _type], up[k[0], _type] = _low[_type], _up[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(noise_levels))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25, 4))\n",
    "for _type in range(4):\n",
    "    _m = [mean[l, _type] for l in noise_levels]\n",
    "    _l = [low[l, _type] for l in noise_levels]\n",
    "    _u = [up[l, _type] for l in noise_levels]\n",
    "    ax[_type].plot(x, _l, label='Lower', lw=3, color='g')\n",
    "    ax[_type].plot(x, _u, label='Upper', lw=3, color='b')\n",
    "    ax[_type].plot(x, _m, label='Mean', lw=3, color='r')\n",
    "    ax[_type].fill_between(x, _l, _u, color='r', alpha=0.2)\n",
    "    ax[_type].set(xticks=x, xticklabels=x_ax)\n",
    "    if _type == 0:\n",
    "        ax[_type].title.set_text('Normal Data')\n",
    "    else:\n",
    "        ax[_type].title.set_text(f'Attack Data {_type}')\n",
    "    ax[_type].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
